# Decision Tree

A decision tree tests inputs and branches to other conditions to conduct more tests, till reaching leaf nodes.

It attempts to find conditions with large value uncertainty/entropy and splits into branches to lower uncertainty, such as by Gini Impurity or Information Gain.

## Gini Impurity

Gini Impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset.

## Information Gain

Information gain is based on the concept of entropy and information content from information theory.